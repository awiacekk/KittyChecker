{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1824931d",
   "metadata": {
    "papermill": {
     "duration": 0.006132,
     "end_time": "2024-01-19T13:16:12.923842",
     "exception": false,
     "start_time": "2024-01-19T13:16:12.917710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Pierwszym krokiem jest przygotowanie zdjęć do analizy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6046580a",
   "metadata": {
    "papermill": {
     "duration": 0.005322,
     "end_time": "2024-01-19T13:16:12.934940",
     "exception": false,
     "start_time": "2024-01-19T13:16:12.929618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Importy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87b09114",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T13:16:12.946928Z",
     "iopub.status.busy": "2024-01-19T13:16:12.946575Z",
     "iopub.status.idle": "2024-01-19T13:16:33.652948Z",
     "shell.execute_reply": "2024-01-19T13:16:33.652057Z"
    },
    "papermill": {
     "duration": 20.715235,
     "end_time": "2024-01-19T13:16:33.655443",
     "exception": false,
     "start_time": "2024-01-19T13:16:12.940208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import keras\n",
    "import sklearn\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4439d0",
   "metadata": {
    "papermill": {
     "duration": 0.005526,
     "end_time": "2024-01-19T13:16:33.666641",
     "exception": false,
     "start_time": "2024-01-19T13:16:33.661115",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Wybranie ścieżek oraz docelowego rozmiaru zdjęć kotów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfe740e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T13:16:33.678816Z",
     "iopub.status.busy": "2024-01-19T13:16:33.678268Z",
     "iopub.status.idle": "2024-01-19T13:16:33.682938Z",
     "shell.execute_reply": "2024-01-19T13:16:33.682066Z"
    },
    "papermill": {
     "duration": 0.012794,
     "end_time": "2024-01-19T13:16:33.684848",
     "exception": false,
     "start_time": "2024-01-19T13:16:33.672054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "breeds_folder = '/kaggle/input/cats-breed-dataset/cat_v1'\n",
    "output_folder = '/kaggle/working/train'\n",
    "\n",
    "target_size = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0c9463",
   "metadata": {
    "papermill": {
     "duration": 0.005477,
     "end_time": "2024-01-19T13:16:33.695762",
     "exception": false,
     "start_time": "2024-01-19T13:16:33.690285",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Następnie iterujemy po folderach i dokonujemy zmian w rozmiarze zdjęcia. Tworzymy także podfoldery raz w folderze wyjściowym. Z powodu istnienia plików o nieprawidłowym rozszerzeniu, musimy też je odfiltrować."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbe36b93",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-19T13:16:33.708731Z",
     "iopub.status.busy": "2024-01-19T13:16:33.708436Z",
     "iopub.status.idle": "2024-01-19T13:16:34.140629Z",
     "shell.execute_reply": "2024-01-19T13:16:34.139743Z"
    },
    "papermill": {
     "duration": 0.441554,
     "end_time": "2024-01-19T13:16:34.143030",
     "exception": false,
     "start_time": "2024-01-19T13:16:33.701476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "breeds_folder = '/kaggle/input/cats-breed-dataset/cat_v1'\n",
    "\n",
    "for breed_folder in os.listdir(breeds_folder):\n",
    "    breed_images = os.listdir(os.path.join(breeds_folder, breed_folder))\n",
    "    all_images.extend([os.path.join(breeds_folder, breed_folder, img) for img in breed_images])\n",
    "    all_labels.extend([breed_folder]*len(breed_images))\n",
    "\n",
    "df = pd.DataFrame({'filename': all_images, 'class': all_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84df1de0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T13:16:34.156700Z",
     "iopub.status.busy": "2024-01-19T13:16:34.156022Z",
     "iopub.status.idle": "2024-01-19T13:16:34.204121Z",
     "shell.execute_reply": "2024-01-19T13:16:34.203097Z"
    },
    "papermill": {
     "duration": 0.057194,
     "end_time": "2024-01-19T13:16:34.206369",
     "exception": false,
     "start_time": "2024-01-19T13:16:34.149175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/cats-breed-dataset/cat_v1/maine_...</td>\n",
       "      <td>maine_coon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/cats-breed-dataset/cat_v1/bengal...</td>\n",
       "      <td>bengal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/cats-breed-dataset/cat_v1/ragdol...</td>\n",
       "      <td>ragdoll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/cats-breed-dataset/cat_v1/ragdol...</td>\n",
       "      <td>ragdoll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/cats-breed-dataset/cat_v1/bengal...</td>\n",
       "      <td>bengal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/kaggle/input/cats-breed-dataset/cat_v1/domest...</td>\n",
       "      <td>domestic_shorthair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/kaggle/input/cats-breed-dataset/cat_v1/ragdol...</td>\n",
       "      <td>ragdoll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/kaggle/input/cats-breed-dataset/cat_v1/bengal...</td>\n",
       "      <td>bengal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/kaggle/input/cats-breed-dataset/cat_v1/ragdol...</td>\n",
       "      <td>ragdoll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/kaggle/input/cats-breed-dataset/cat_v1/maine_...</td>\n",
       "      <td>maine_coon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename               class\n",
       "0  /kaggle/input/cats-breed-dataset/cat_v1/maine_...          maine_coon\n",
       "1  /kaggle/input/cats-breed-dataset/cat_v1/bengal...              bengal\n",
       "2  /kaggle/input/cats-breed-dataset/cat_v1/ragdol...             ragdoll\n",
       "3  /kaggle/input/cats-breed-dataset/cat_v1/ragdol...             ragdoll\n",
       "4  /kaggle/input/cats-breed-dataset/cat_v1/bengal...              bengal\n",
       "5  /kaggle/input/cats-breed-dataset/cat_v1/domest...  domestic_shorthair\n",
       "6  /kaggle/input/cats-breed-dataset/cat_v1/ragdol...             ragdoll\n",
       "7  /kaggle/input/cats-breed-dataset/cat_v1/bengal...              bengal\n",
       "8  /kaggle/input/cats-breed-dataset/cat_v1/ragdol...             ragdoll\n",
       "9  /kaggle/input/cats-breed-dataset/cat_v1/maine_...          maine_coon"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')\n",
    "for x in df.filename:\n",
    "    if not x.lower().endswith(valid_extensions):\n",
    "        df = df.drop(df[df.filename == x].index)\n",
    "df = df.sample(frac=1)\n",
    "df = df.reset_index(drop=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "431f32d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T13:16:34.219258Z",
     "iopub.status.busy": "2024-01-19T13:16:34.218958Z",
     "iopub.status.idle": "2024-01-19T13:16:34.256138Z",
     "shell.execute_reply": "2024-01-19T13:16:34.255395Z"
    },
    "papermill": {
     "duration": 0.045922,
     "end_time": "2024-01-19T13:16:34.258155",
     "exception": false,
     "start_time": "2024-01-19T13:16:34.212233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 760 validated image filenames belonging to 5 classes.\n",
      "Found 191 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['class'], random_state=42)\n",
    "\n",
    "input_shape = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df, \n",
    "                                                    x_col='filename', \n",
    "                                                    y_col='class', \n",
    "                                                    target_size=target_size, \n",
    "                                                    batch_size=batch_size, \n",
    "                                                    color_mode='rgb',\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)\n",
    "val_generator = val_datagen.flow_from_dataframe(val_df, \n",
    "                                                x_col='filename', \n",
    "                                                y_col='class', \n",
    "                                                target_size=target_size, \n",
    "                                                batch_size=batch_size, \n",
    "                                                color_mode='rgb',\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)\n",
    "num_classes = train_df['class'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b7464e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T13:16:34.271819Z",
     "iopub.status.busy": "2024-01-19T13:16:34.271528Z",
     "iopub.status.idle": "2024-01-19T13:16:34.278333Z",
     "shell.execute_reply": "2024-01-19T13:16:34.277465Z"
    },
    "papermill": {
     "duration": 0.015947,
     "end_time": "2024-01-19T13:16:34.280326",
     "exception": false,
     "start_time": "2024-01-19T13:16:34.264379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bengal': 0,\n",
       " 'domestic_shorthair': 1,\n",
       " 'maine_coon': 2,\n",
       " 'ragdoll': 3,\n",
       " 'siamese': 4}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = list(train_generator.class_indices.keys())\n",
    "values = list(train_generator.class_indices.values())\n",
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41df6b51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T13:16:34.294630Z",
     "iopub.status.busy": "2024-01-19T13:16:34.294300Z",
     "iopub.status.idle": "2024-01-19T13:16:34.307429Z",
     "shell.execute_reply": "2024-01-19T13:16:34.306473Z"
    },
    "papermill": {
     "duration": 0.022882,
     "end_time": "2024-01-19T13:16:34.309514",
     "exception": false,
     "start_time": "2024-01-19T13:16:34.286632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Breed</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bengal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>domestic_shorthair</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maine_coon</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ragdoll</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>siamese</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Breed  Index\n",
       "0              bengal      0\n",
       "1  domestic_shorthair      1\n",
       "2          maine_coon      2\n",
       "3             ragdoll      3\n",
       "4             siamese      4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Breed':keys,\n",
    "                'Index':values})\n",
    "df.to_csv('indexes.csv', encoding='utf-8', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eb60e6",
   "metadata": {
    "papermill": {
     "duration": 0.006316,
     "end_time": "2024-01-19T13:16:34.322607",
     "exception": false,
     "start_time": "2024-01-19T13:16:34.316291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Następnie przechodzimy do przygotowania zdjęć w folderze wyjściowym."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8426c3",
   "metadata": {
    "papermill": {
     "duration": 0.006447,
     "end_time": "2024-01-19T13:16:34.335105",
     "exception": false,
     "start_time": "2024-01-19T13:16:34.328658",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Tworzenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74a77394",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T13:16:34.349659Z",
     "iopub.status.busy": "2024-01-19T13:16:34.349343Z",
     "iopub.status.idle": "2024-01-19T13:24:12.293145Z",
     "shell.execute_reply": "2024-01-19T13:24:12.292186Z"
    },
    "papermill": {
     "duration": 457.967912,
     "end_time": "2024-01-19T13:24:12.309609",
     "exception": false,
     "start_time": "2024-01-19T13:16:34.341697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29084464/29084464 [==============================] - 0s 0us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 68s 2s/step - loss: 19.8119 - accuracy: 0.4519 - val_loss: 2.4346 - val_accuracy: 0.7625\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 44s 2s/step - loss: 2.0619 - accuracy: 0.7734 - val_loss: 0.9716 - val_accuracy: 0.7812\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 44s 2s/step - loss: 0.5111 - accuracy: 0.8407 - val_loss: 0.6521 - val_accuracy: 0.8062\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 43s 2s/step - loss: 0.3817 - accuracy: 0.8805 - val_loss: 0.5068 - val_accuracy: 0.8562\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 41s 2s/step - loss: 0.3156 - accuracy: 0.8777 - val_loss: 0.5438 - val_accuracy: 0.8375\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 42s 2s/step - loss: 0.2757 - accuracy: 0.8984 - val_loss: 0.5560 - val_accuracy: 0.8375\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 43s 2s/step - loss: 0.2467 - accuracy: 0.9217 - val_loss: 0.6813 - val_accuracy: 0.8000\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 43s 2s/step - loss: 0.2231 - accuracy: 0.9354 - val_loss: 0.5616 - val_accuracy: 0.8562\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 42s 2s/step - loss: 0.1965 - accuracy: 0.9299 - val_loss: 0.6159 - val_accuracy: 0.8375\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 41s 2s/step - loss: 0.1530 - accuracy: 0.9327 - val_loss: 0.6210 - val_accuracy: 0.8500\n"
     ]
    }
   ],
   "source": [
    "baseModel = DenseNet121(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "headModel = baseModel.output\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(num_classes, activation=\"softmax\")(headModel)\n",
    "\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "for layer in model.layers[:-8]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // batch_size,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfc380eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T13:24:12.413849Z",
     "iopub.status.busy": "2024-01-19T13:24:12.412948Z",
     "iopub.status.idle": "2024-01-19T13:24:13.817849Z",
     "shell.execute_reply": "2024-01-19T13:24:13.817042Z"
    },
    "papermill": {
     "duration": 1.482879,
     "end_time": "2024-01-19T13:24:13.820274",
     "exception": false,
     "start_time": "2024-01-19T13:24:12.337395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('models/densenet121.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa31f369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T13:24:13.878251Z",
     "iopub.status.busy": "2024-01-19T13:24:13.877861Z",
     "iopub.status.idle": "2024-01-19T13:31:27.729431Z",
     "shell.execute_reply": "2024-01-19T13:31:27.728408Z"
    },
    "papermill": {
     "duration": 433.928214,
     "end_time": "2024-01-19T13:31:27.776550",
     "exception": false,
     "start_time": "2024-01-19T13:24:13.848336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "171446536/171446536 [==============================] - 1s 0us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 54s 2s/step - loss: 8.6346 - accuracy: 0.2679 - val_loss: 2.0056 - val_accuracy: 0.1937\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 42s 2s/step - loss: 1.5302 - accuracy: 0.2962 - val_loss: 1.7051 - val_accuracy: 0.1875\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 42s 2s/step - loss: 1.5115 - accuracy: 0.3008 - val_loss: 1.4970 - val_accuracy: 0.3125\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 40s 2s/step - loss: 1.4762 - accuracy: 0.3255 - val_loss: 1.4920 - val_accuracy: 0.2750\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 41s 2s/step - loss: 1.4529 - accuracy: 0.3420 - val_loss: 1.5588 - val_accuracy: 0.2875\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 41s 2s/step - loss: 1.4703 - accuracy: 0.3613 - val_loss: 1.5080 - val_accuracy: 0.3688\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 43s 2s/step - loss: 1.4140 - accuracy: 0.3819 - val_loss: 1.4200 - val_accuracy: 0.4187\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 40s 2s/step - loss: 1.3826 - accuracy: 0.3709 - val_loss: 1.4853 - val_accuracy: 0.4187\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 41s 2s/step - loss: 1.4128 - accuracy: 0.3764 - val_loss: 1.4352 - val_accuracy: 0.3500\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 43s 2s/step - loss: 1.4222 - accuracy: 0.3874 - val_loss: 1.4354 - val_accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "baseModel = ResNet101(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "headModel = baseModel.output\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(num_classes, activation=\"softmax\")(headModel)\n",
    "\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "for layer in model.layers[:-8]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59c44df4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T13:31:27.875284Z",
     "iopub.status.busy": "2024-01-19T13:31:27.874862Z",
     "iopub.status.idle": "2024-01-19T13:31:29.970197Z",
     "shell.execute_reply": "2024-01-19T13:31:29.969151Z"
    },
    "papermill": {
     "duration": 2.147612,
     "end_time": "2024-01-19T13:31:29.972510",
     "exception": false,
     "start_time": "2024-01-19T13:31:27.824898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('models/resnet101.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2ab1f61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T13:31:30.075759Z",
     "iopub.status.busy": "2024-01-19T13:31:30.075382Z",
     "iopub.status.idle": "2024-01-19T13:38:41.685853Z",
     "shell.execute_reply": "2024-01-19T13:38:41.684884Z"
    },
    "papermill": {
     "duration": 431.664494,
     "end_time": "2024-01-19T13:38:41.688101",
     "exception": false,
     "start_time": "2024-01-19T13:31:30.023607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 0s 0us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 50s 2s/step - loss: 15.3957 - accuracy: 0.5755 - val_loss: 5.5368 - val_accuracy: 0.7312\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 39s 2s/step - loss: 4.2819 - accuracy: 0.7541 - val_loss: 1.8578 - val_accuracy: 0.7937\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 42s 2s/step - loss: 1.1636 - accuracy: 0.8365 - val_loss: 0.8464 - val_accuracy: 0.8125\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 43s 2s/step - loss: 0.5072 - accuracy: 0.8585 - val_loss: 0.5885 - val_accuracy: 0.8375\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 43s 2s/step - loss: 0.2846 - accuracy: 0.9176 - val_loss: 0.5841 - val_accuracy: 0.8313\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 42s 2s/step - loss: 0.2265 - accuracy: 0.9231 - val_loss: 0.6696 - val_accuracy: 0.8313\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 41s 2s/step - loss: 0.2002 - accuracy: 0.9286 - val_loss: 0.6504 - val_accuracy: 0.8313\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 43s 2s/step - loss: 0.1872 - accuracy: 0.9272 - val_loss: 0.7061 - val_accuracy: 0.8375\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 42s 2s/step - loss: 0.2179 - accuracy: 0.9190 - val_loss: 0.8191 - val_accuracy: 0.8000\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 42s 2s/step - loss: 0.2153 - accuracy: 0.9354 - val_loss: 0.9165 - val_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "baseModel = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "input_shape = (224, 224)\n",
    "\n",
    "headModel = baseModel.output\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(num_classes, activation=\"softmax\")(headModel)\n",
    "\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "for layer in model.layers[:-8]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82b4e349",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-19T13:38:41.830984Z",
     "iopub.status.busy": "2024-01-19T13:38:41.830109Z",
     "iopub.status.idle": "2024-01-19T13:38:43.006506Z",
     "shell.execute_reply": "2024-01-19T13:38:43.005676Z"
    },
    "papermill": {
     "duration": 1.25034,
     "end_time": "2024-01-19T13:38:43.008850",
     "exception": false,
     "start_time": "2024-01-19T13:38:41.758510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('models/inceptionV3.h5')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3015664,
     "sourceId": 5186873,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1358.034719,
   "end_time": "2024-01-19T13:38:46.235097",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-19T13:16:08.200378",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
